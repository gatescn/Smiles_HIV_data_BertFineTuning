{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gatescn/Smiles_HIV_data_BertFineTuning/blob/main/SMILES_transformer_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_lightning\n",
        "!pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGM7X5gR_h4Q",
        "outputId": "978ee2b5-23a9-49e3-811d-547381fe39ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.66.6)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.10.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (0.11.9)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.11.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch_lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch_lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch_lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F3h29m-JfuD",
        "outputId": "9ba79210-fb81-44e1-8d27-c392d9537126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torchmetrics\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from torch import nn\n",
        "from transformers import BertModel, BertTokenizer, BertConfig, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchmetrics.classification import BinaryAUROC\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import random\n",
        "import warnings\n",
        "import gc\n",
        "\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "import random\n",
        "\n",
        "# Define the source and destination directories\n",
        "current_datetime = datetime.now().strftime(\"%m%d%Y\")\n",
        "\n",
        "unique_identifier = f\"{random.randint(1, 9999)}_{datetime.now().strftime('%S')}\"\n",
        "\n",
        "LABEL_COLUMNS = [\"HIV_active\"]\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "MODEL_NAME = 'bert-base-uncased'\n",
        "LOG_OUTPUT_PATH = '/content/gdrive/MyDrive/SMILETransformerHistoricLogs/tb_logs_data_'+current_datetime+'_'+unique_identifier\n",
        "batch_size=30\n",
        "n_epochs=1\n",
        "learning_rate=1e-3\n",
        "source_dir = \"/tb_logs\"\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "      dirpath= CHECKPOINT_PATH,\n",
        "      filename='{epoch}-{val_loss:.2f}',\n",
        "      save_top_k=1,\n",
        "      monitor='val_loss',\n",
        "      mode='min'\n",
        ")\n"
      ],
      "metadata": {
        "id": "mjuBMX8GUr6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Google colab commands\n",
        "#!nvidia-smi\n",
        "#torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz7F2vuEjVlX",
        "outputId": "370935f1-6444-41c4-eea9-f312303e7a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec  6 21:01:14 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.cuda.memory_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "1XjDfGWZTdWk",
        "outputId": "4f7c79f1-7e5d-476a-cb04-d487c3246d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\\n|       from large pool |       0    |       0    |       0    |       0    |\\n|       from small pool |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SmilesDataSet(Dataset):\n",
        "\n",
        "    def __init__(self, _data, _tokenizer: BertTokenizer, max_token_length=512):\n",
        "        self.tokenizer = _tokenizer\n",
        "        self.n_samples = _data.shape[0]\n",
        "        self.max_length = max_token_length\n",
        "        self.data = _data\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        data_row = self.data.iloc[index]\n",
        "\n",
        "        smiles_text = data_row.smiles_activity\n",
        "        labels = data_row[LABEL_COLUMNS]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            smiles_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length = self.max_length,\n",
        "            return_token_type_ids=False,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return dict(\n",
        "            smiles_activity = smiles_text,\n",
        "            input_ids=encoding[\"input_ids\"].flatten(),\n",
        "            attention_mask=encoding[\"attention_mask\"].flatten(),\n",
        "            labels=torch.FloatTensor(labels)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "JYDlBD2Hezss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for testing using external data ensure: test_data_dir= (path to test data files), extTest=True\n",
        "class SmilesDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, data_dir,  tokenizer, batch_size, test_data_dir= None, extTest=False, num_workers=7, max_token_length=512):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.test_dir = test_data_dir #if extTest is true, this should be the directory to the external test file\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.max_token_length = max_token_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.extTest = extTest\n",
        "\n",
        "    def create_new_feature(self, df):\n",
        "        # Combine 'smiles' and 'activity' columns into a new feature\n",
        "        df['smiles_activity'] = df['smiles'] + df['activity']\n",
        "        return df\n",
        "\n",
        "    def split_data(self, df, test_size=0.2, random_state=42):\n",
        "        # Split the data into training and validation datasets\n",
        "        train_df, val_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df['HIV_active'])\n",
        "        default_test_df = val_df.sample(frac=0.5, replace=False)\n",
        "        return train_df, val_df, default_test_df\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Load the CSV file into a DataFrame\n",
        "        raw_data = pd.read_csv(self.data_dir)\n",
        "        if self.extTest == True:\n",
        "          raw_test_data = pd.read_csv(self.test_dir)\n",
        "          self.updated_test_data = self.create_new_feature(raw_test_data)\n",
        "          self.updated_test_data = self.updated_test_data[self.updated_test_data['smiles_activity'].str.len() <= 512]\n",
        "\n",
        "        self.updated_data = self.create_new_feature(raw_data)\n",
        "        self.updated_data = self.updated_data[self.updated_data['smiles_activity'].str.len() <= 512]\n",
        "        train_d, val_d, def_test_df = self.split_data(self.updated_data)\n",
        "        self.train_dataset = SmilesDataSet(_data=train_d, _tokenizer=self.tokenizer)\n",
        "        self.val_dataset = SmilesDataSet(_data=val_d, _tokenizer=self.tokenizer)\n",
        "        if self.extTest == True:\n",
        "          sample_df = self.updated_test_data.sample(frac=0.5, replace=False)\n",
        "          self.test_dataset = SmilesDataSet(_data=sample_df, _tokenizer=self.tokenizer)\n",
        "        else:\n",
        "          self.test_dataset = SmilesDataSet(_data=def_test_df, _tokenizer=self.tokenizer) #will be overrided if extTest is true\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=self.num_workers,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            num_workers=2,\n",
        "            shuffle=False\n",
        "        )\n",
        "    def test_dataloader(self):\n",
        "      return DataLoader(\n",
        "          self.test_dataset,\n",
        "          batch_size=self.batch_size,\n",
        "          num_workers=2,\n",
        "          shuffle=False\n",
        "      )\n",
        "\n",
        "    def get_training_data(self):\n",
        "        return self.train_dataset\n",
        "\n",
        "    def get_validation_data(self):\n",
        "        return self.val_dataset\n",
        "\n",
        "    def get_training_dataloader(self):\n",
        "      return self.train_dataloader"
      ],
      "metadata": {
        "id": "n8-7Dwzje2cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SmilesTransformerClassifier(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, model_name = MODEL_NAME, learning_rate=2e-5, steps_per_epoch=None, n_epochs=None):\n",
        "        super().__init__()\n",
        "        config = BertConfig.from_pretrained(model_name)\n",
        "        config.return_dict = True\n",
        "        #config.max_position_embeddings = 600 - if we want to go above the 512 limit\n",
        "        self.bert = BertModel.from_pretrained(model_name, config= config, ignore_mismatched_sizes=True)\n",
        "        print(\"using model:\"+model_name)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, 1) #this will serve as way for us to get the outputs of the bert model and cinvert those into the number of classes in which we will need to predict\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.n_epochs = n_epochs\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.training_steps_outputs = []\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    #we will computer the loss in this method, standard in all tutorials about this fine tuning.\n",
        "    # it will be none during inference, and some value when doing training.\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "         output = self.bert(input_ids, attention_mask=attention_mask)\n",
        "         output = self.classifier(output.pooler_output)#used the pooled result from bert, #run the linear layer on top of output\n",
        "         output = torch.sigmoid(output) #apply sigmoid function\n",
        "         loss = 0\n",
        "         if labels is not None: #if we have labels, compute the loss itself\n",
        "            loss = self.criterion(output, labels)\n",
        "         return loss, output #loss and output or prediction of the model\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"] #our data from our dataset is the batch (ref: get__item from SmilesDataSet class)\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        loss, outputs = self.forward(input_ids, attention_mask, labels)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, logger=True) #outputs the loss so we can see it, and track the progress\n",
        "        self.training_steps_outputs.append({\"labels\":labels, \"predictions\":outputs})\n",
        "        return{\"loss\": loss, \"predictions\": outputs, \"labels\": labels} #return a dictionary of values, will use later\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"] #our data from our dataset is the batch (ref: get__item from SmilesDataSet class)\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        loss, outputs = self.forward(input_ids, attention_mask, labels)\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, logger=True) #outputs the loss so we can see it, and track the progress\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input_ids = batch[\"input_ids\"] #our data from our dataset is the batch (ref: get__item from SmilesDataSet class)\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        loss, outputs = self.forward(input_ids, attention_mask, labels)\n",
        "        self.log(\"test_loss\", loss, prog_bar=True, logger=True) #outputs the loss so we can see it, and track the progress\n",
        "        return loss\n",
        "\n",
        "    #training epoch end: we will compute the roc score at the end of each epoch\n",
        "    def on_train_epoch_end(self):\n",
        "        labels = []\n",
        "        predictions = []\n",
        "\n",
        "        for output in self.training_steps_outputs:\n",
        "            #.detach().cpu()\n",
        "            for out_labels in output[\"labels\"].detach().cpu():\n",
        "                labels.append(out_labels)\n",
        "            for out_predictions in output[\"predictions\"].detach().cpu():\n",
        "                predictions.append(out_predictions)\n",
        "\n",
        "        labels = torch.stack(labels) #flatten\n",
        "        predictions = torch.stack(predictions) #flatten\n",
        "\n",
        "        auroc = BinaryAUROC()\n",
        "        roc_score = auroc(predictions[:, 0], labels[:,0])\n",
        "        self.logger.experiment.add_scalar(f\"HIV_active_roc_auc/Train\", roc_score, self.current_epoch)\n",
        "        self.training_steps_outputs.clear()\n",
        "        gc.collect()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr= self.learning_rate)\n",
        "        warmup_steps = self.steps_per_epoch // 3\n",
        "        total_steps = self.steps_per_epoch * self.n_epochs - warmup_steps\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optimizer,\n",
        "            warmup_steps,\n",
        "            total_steps\n",
        "        )\n",
        "        return [optimizer], [scheduler]"
      ],
      "metadata": {
        "id": "OA9oiHfUe54f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6La1n0_S_hI5"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
        "dm = SmilesDataModule(data_dir='./HIV.csv',\n",
        "                      batch_size= batch_size,\n",
        "                      tokenizer=tokenizer,\n",
        "                      test_data_dir= './Shuffled_HIV.csv',\n",
        "                      extTest=True)\n",
        "dm.prepare_data()\n",
        "dm.setup()\n",
        "data_size = len(dm.train_dataset)\n",
        "steps_per_epoch = data_size // batch_size\n",
        "\n",
        "model = SmilesTransformerClassifier(steps_per_epoch=steps_per_epoch, n_epochs=n_epochs, learning_rate=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the TensorBoard logger\n",
        "logger = TensorBoardLogger(\"tb_logs\", name=\"SMILES Transformer Model\")\n",
        "trainer = pl.Trainer(max_epochs=n_epochs, callbacks=[checkpoint_callback], logger=logger, accelerator=\"gpu\")\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir tb_logs\n",
        "trainer.fit(model,dm)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "result = trainer.test(model,dm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288,
          "referenced_widgets": [
            "571dbd0a841a47028397e9f76ec122ff",
            "922e572f13ca42c8a4da85c4dd5637cf",
            "8391ee622c8b4151b2b49a4de6ac730e",
            "dfa578e75abb4e06b2aeaf8ff6f30116",
            "29742b704de94edcbe01c36399667ffb",
            "32bc865d912248529c4095ccb0f2ce07",
            "519016fe3e55485185e55c061ffde521",
            "8c0430708660459b9f5ac3439466363a",
            "6b6e33b8b15440379996044a64ef3a65",
            "8d095e700e5246d68748e5b01d021d3e",
            "bf181c1e8f414bf7b9b4b3d4b33bd2bb"
          ]
        },
        "id": "S7uo7rhSze8l",
        "outputId": "1a88efd4-5786-4b83-e6e4-e71ad225e7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Testing: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "571dbd0a841a47028397e9f76ec122ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7003675103187561    \u001b[0m\u001b[35m \u001b[0m│\n",
              "└───────────────────────────┴───────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7003675103187561     </span>│\n",
              "└───────────────────────────┴───────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-67669c45969a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QYGfrZEIckxJ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "94d6b50e951407cbcad8d1b7fe40af3392a0c80ae5183f1f6a3d5ac6f5f28f64"
      }
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "571dbd0a841a47028397e9f76ec122ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_922e572f13ca42c8a4da85c4dd5637cf",
              "IPY_MODEL_8391ee622c8b4151b2b49a4de6ac730e",
              "IPY_MODEL_dfa578e75abb4e06b2aeaf8ff6f30116"
            ],
            "layout": "IPY_MODEL_29742b704de94edcbe01c36399667ffb"
          }
        },
        "922e572f13ca42c8a4da85c4dd5637cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32bc865d912248529c4095ccb0f2ce07",
            "placeholder": "​",
            "style": "IPY_MODEL_519016fe3e55485185e55c061ffde521",
            "value": "Testing: "
          }
        },
        "8391ee622c8b4151b2b49a4de6ac730e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c0430708660459b9f5ac3439466363a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b6e33b8b15440379996044a64ef3a65",
            "value": 1
          }
        },
        "dfa578e75abb4e06b2aeaf8ff6f30116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d095e700e5246d68748e5b01d021d3e",
            "placeholder": "​",
            "style": "IPY_MODEL_bf181c1e8f414bf7b9b4b3d4b33bd2bb",
            "value": " 1360/? [18:50&lt;00:00,  1.20it/s]"
          }
        },
        "29742b704de94edcbe01c36399667ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "32bc865d912248529c4095ccb0f2ce07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "519016fe3e55485185e55c061ffde521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c0430708660459b9f5ac3439466363a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b6e33b8b15440379996044a64ef3a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d095e700e5246d68748e5b01d021d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf181c1e8f414bf7b9b4b3d4b33bd2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}